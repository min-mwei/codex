#!/usr/bin/env python3
"""Run lightweight dynamic pentest probes against a deployed webapp target."""

from __future__ import annotations

import argparse
import json
import re
import subprocess
import sys
import urllib.error
import urllib.parse
import urllib.request
from dataclasses import asdict, dataclass
from html.parser import HTMLParser
from http.cookiejar import CookieJar
from pathlib import Path
from typing import Dict, List, Tuple

CONTEXT_ROOT = Path("/vorpal_base/context").resolve()
CACHE_ROOT = CONTEXT_ROOT / ".cobalt"
INVICTUS_SCRIPT_PATH = Path("/vorpal_base/skills/invictus/scripts/scan_owasp_top10.py")

DEFAULT_YEAR = 2017
DEFAULT_MAX_LINKS = 3
DEFAULT_TIMEOUT = 15
MAX_BODY_BYTES = 2_000_000

USER_AGENT = (
    "Mozilla/5.0 (X11; Linux x86_64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/122.0.0.0 Safari/537.36"
)

FALLBACK_2017 = {
    "1": "Injection",
    "2": "Broken Authentication",
    "3": "Sensitive Data Exposure",
    "4": "XML External Entities (XXE)",
    "5": "Broken Access Control",
    "6": "Security Misconfiguration",
    "7": "Cross-Site Scripting (XSS)",
    "8": "Insecure Deserialization",
    "9": "Using Components with Known Vulnerabilities",
    "10": "Insufficient Logging and Monitoring",
}

SEVERITY_ORDER = {
    "critical": 0,
    "high": 1,
    "medium": 2,
    "low": 3,
}

SQL_ERROR_PATTERNS = [
    re.compile(r"you have an error in your sql syntax", re.IGNORECASE),
    re.compile(r"warning:\s*mysql_", re.IGNORECASE),
    re.compile(r"mysql_fetch", re.IGNORECASE),
    re.compile(r"unclosed quotation mark after the character string", re.IGNORECASE),
    re.compile(r"sqlite error", re.IGNORECASE),
    re.compile(r"sqlstate\[[0-9a-z]+\]", re.IGNORECASE),
]

ERROR_DISCLOSURE_PATTERNS = [
    re.compile(r"traceback \(most recent call last\)", re.IGNORECASE),
    re.compile(r"fatal error:\s*uncaught", re.IGNORECASE),
    re.compile(r"stack trace", re.IGNORECASE),
    re.compile(r"\bexception\b", re.IGNORECASE),
]


@dataclass
class HttpResponse:
    status: int
    url: str
    headers: Dict[str, List[str]]
    body: str


@dataclass
class FormField:
    name: str
    value: str
    field_type: str


@dataclass
class ParsedForm:
    action: str
    method: str
    fields: List[FormField]


@dataclass
class Finding:
    rule_id: str
    rank: int
    category: str
    severity: str
    title: str
    endpoint: str
    evidence: str
    recommendation: str


class FormParser(HTMLParser):
    """Extract form/input metadata needed for login and CSRF checks."""

    def __init__(self) -> None:
        super().__init__()
        self.forms: List[ParsedForm] = []
        self._current: ParsedForm | None = None

    def handle_starttag(self, tag: str, attrs) -> None:
        attrs_dict = {k.lower(): (v or "") for k, v in attrs}
        tag_lower = tag.lower()

        if tag_lower == "form":
            action = attrs_dict.get("action", "")
            method = (attrs_dict.get("method", "get") or "get").lower()
            self._current = ParsedForm(action=action, method=method, fields=[])
            return

        if self._current is None:
            return

        if tag_lower == "input":
            name = attrs_dict.get("name", "").strip()
            if not name:
                return
            value = attrs_dict.get("value", "")
            field_type = (attrs_dict.get("type", "text") or "text").lower()
            self._current.fields.append(
                FormField(name=name, value=value, field_type=field_type)
            )
            return

        if tag_lower in {"textarea", "select"}:
            name = attrs_dict.get("name", "").strip()
            if not name:
                return
            self._current.fields.append(
                FormField(name=name, value="", field_type=tag_lower)
            )

    def handle_endtag(self, tag: str) -> None:
        if tag.lower() == "form" and self._current is not None:
            self.forms.append(self._current)
            self._current = None


class WebClient:
    """Simple HTTP client with cookie support and browser-like User-Agent."""

    def __init__(self, timeout: int) -> None:
        self.timeout = timeout
        self.cookie_jar = CookieJar()
        self.opener = urllib.request.build_opener(
            urllib.request.HTTPCookieProcessor(self.cookie_jar)
        )

    def get(self, url: str, params: Dict[str, str] | None = None) -> HttpResponse:
        if params:
            url = append_query(url, params)
        return self._request("GET", url, None)

    def post(self, url: str, form: Dict[str, str]) -> HttpResponse:
        encoded = urllib.parse.urlencode(form).encode("utf-8")
        return self._request(
            "POST",
            url,
            encoded,
            {"Content-Type": "application/x-www-form-urlencoded"},
        )

    def _request(
        self,
        method: str,
        url: str,
        body: bytes | None,
        extra_headers: Dict[str, str] | None = None,
    ) -> HttpResponse:
        headers = {"User-Agent": USER_AGENT}
        if extra_headers:
            headers.update(extra_headers)
        request = urllib.request.Request(
            url=url,
            data=body,
            headers=headers,
            method=method,
        )

        try:
            with self.opener.open(request, timeout=self.timeout) as response:
                payload = response.read(MAX_BODY_BYTES)
                charset = response.headers.get_content_charset() or "utf-8"
                text = payload.decode(charset, errors="replace")
                return HttpResponse(
                    status=response.getcode() or 0,
                    url=response.geturl(),
                    headers=normalize_headers(response.headers),
                    body=text,
                )
        except urllib.error.HTTPError as exc:
            payload = exc.read(MAX_BODY_BYTES)
            charset = exc.headers.get_content_charset() or "utf-8"
            text = payload.decode(charset, errors="replace")
            return HttpResponse(
                status=exc.code,
                url=exc.geturl(),
                headers=normalize_headers(exc.headers),
                body=text,
            )
        except Exception as exc:
            raise RuntimeError(f"{method} {url} failed: {exc}") from exc


def normalize_headers(headers) -> Dict[str, List[str]]:
    result: Dict[str, List[str]] = {}
    for key, value in headers.items():
        result.setdefault(key.lower(), []).append(value)
    return result


def normalize_target_url(raw: str) -> str:
    value = raw.strip()
    if not value:
        raise ValueError("Target URL is empty.")
    if "://" not in value:
        value = "http://" + value

    parsed = urllib.parse.urlparse(value)
    if not parsed.scheme or not parsed.netloc:
        raise ValueError(f"Invalid target URL: {raw}")

    path = parsed.path or "/"
    return urllib.parse.urlunparse(
        (parsed.scheme, parsed.netloc, path, "", "", "")
    )


def derive_app_base(url: str) -> str:
    parsed = urllib.parse.urlparse(url)
    path = parsed.path or "/"
    if path.endswith("/"):
        base_path = path
    else:
        slash = path.rfind("/")
        base_path = path[: slash + 1] if slash >= 0 else "/"

    if not base_path.startswith("/"):
        base_path = "/" + base_path

    return urllib.parse.urlunparse(
        (parsed.scheme, parsed.netloc, base_path, "", "", "")
    )


def append_query(url: str, params: Dict[str, str]) -> str:
    parsed = urllib.parse.urlparse(url)
    query = urllib.parse.parse_qs(parsed.query, keep_blank_values=True)
    for key, value in params.items():
        query[key] = [value]
    encoded = urllib.parse.urlencode(query, doseq=True)
    return urllib.parse.urlunparse(
        (
            parsed.scheme,
            parsed.netloc,
            parsed.path,
            parsed.params,
            encoded,
            parsed.fragment,
        )
    )


def parse_owasp_output(output: str) -> Tuple[List[str], Dict[str, str]]:
    links: List[str] = []
    top10: Dict[str, str] = {}

    link_re = re.compile(r"^\d+\.\s+(https?://\S+)$")
    merged_re = re.compile(r"^A(10|[1-9]):\s*(.*?)\s+\[[^\]]+\]\s*$")

    for raw in output.splitlines():
        line = raw.strip()
        link_match = link_re.match(line)
        if link_match:
            links.append(link_match.group(1))
            continue
        merged_match = merged_re.match(line)
        if merged_match:
            rank = merged_match.group(1)
            name = merged_match.group(2).strip()
            top10[rank] = name

    return links, top10


def ensure_owasp_data(
    year: int,
    max_links: int,
    refresh: bool,
) -> Tuple[Dict[str, object], bool]:
    CACHE_ROOT.mkdir(parents=True, exist_ok=True)
    cache_path = CACHE_ROOT / f"owasp_top10_{year}.json"

    if cache_path.exists() and not refresh:
        data = json.loads(cache_path.read_text(encoding="utf-8"))
        return data, True

    if not INVICTUS_SCRIPT_PATH.exists():
        raise RuntimeError(
            f"Required script not found: {INVICTUS_SCRIPT_PATH}. "
            "Install or restore invictus first."
        )

    query = f"owasp vulnerabilities in {year}"
    cmd = [
        sys.executable,
        str(INVICTUS_SCRIPT_PATH),
        "--query",
        query,
        "--max-links",
        str(max_links),
    ]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    if proc.returncode != 0:
        stderr = proc.stderr.strip() or "(no stderr)"
        raise RuntimeError(f"invictus failed (exit {proc.returncode}): {stderr}")

    links, top10 = parse_owasp_output(proc.stdout)
    if year == 2017:
        for rank, name in FALLBACK_2017.items():
            top10.setdefault(rank, name)

    if len(top10) < 5:
        raise RuntimeError(
            "Could not extract enough OWASP Top 10 entries from invictus output."
        )

    data: Dict[str, object] = {
        "query": query,
        "year": year,
        "links": links[:max_links],
        "top10": top10,
    }
    cache_path.write_text(json.dumps(data, indent=2, sort_keys=True), encoding="utf-8")
    return data, False


def parse_forms(html_text: str) -> List[ParsedForm]:
    parser = FormParser()
    parser.feed(html_text)
    return parser.forms


def extract_token(html_text: str, token_names: set[str] | None = None) -> str | None:
    names = token_names or {"user_token", "csrf_token", "token"}
    for form in parse_forms(html_text):
        for field in form.fields:
            if field.name.lower() in names and field.value:
                return field.value
    return None


def looks_like_login_page(body: str) -> bool:
    lowered = body.lower()
    return (
        'name="username"' in lowered
        and 'name="password"' in lowered
        and "login" in lowered
    )


def is_dvwa_response(response: HttpResponse) -> bool:
    lowered = response.body.lower()
    return (
        "damn vulnerable web application" in lowered
        or "dvwa security" in lowered
        or "dvwa" in lowered
        or "/dvwa/" in response.url.lower()
    )


def get_category_name(top10: Dict[str, str], rank: int) -> str:
    return top10.get(str(rank), FALLBACK_2017.get(str(rank), f"A{rank}"))


def add_finding(
    findings: List[Finding],
    seen: set,
    top10: Dict[str, str],
    *,
    rule_id: str,
    rank: int,
    severity: str,
    title: str,
    endpoint: str,
    evidence: str,
    recommendation: str,
) -> None:
    dedupe_key = (rule_id, endpoint, evidence)
    if dedupe_key in seen:
        return
    seen.add(dedupe_key)
    findings.append(
        Finding(
            rule_id=rule_id,
            rank=rank,
            category=get_category_name(top10, rank),
            severity=severity,
            title=title,
            endpoint=endpoint,
            evidence=evidence,
            recommendation=recommendation,
        )
    )


def find_sql_error(body: str) -> str | None:
    for pattern in SQL_ERROR_PATTERNS:
        match = pattern.search(body)
        if match:
            return match.group(0)
    return None


def run_generic_checks(
    client: WebClient,
    target_url: str,
    first_response: HttpResponse,
    top10: Dict[str, str],
    findings: List[Finding],
    seen: set,
) -> None:
    missing_headers = [
        (
            "content-security-policy",
            "Missing Content-Security-Policy header",
            "medium",
            "Add a strict CSP to reduce XSS impact.",
        ),
        (
            "x-frame-options",
            "Missing X-Frame-Options header",
            "low",
            "Set X-Frame-Options DENY or SAMEORIGIN to mitigate clickjacking.",
        ),
        (
            "x-content-type-options",
            "Missing X-Content-Type-Options header",
            "low",
            "Set X-Content-Type-Options: nosniff.",
        ),
    ]

    for header, title, severity, recommendation in missing_headers:
        if header not in first_response.headers:
            add_finding(
                findings,
                seen,
                top10,
                rule_id=f"header-{header}",
                rank=6,
                severity=severity,
                title=title,
                endpoint=first_response.url,
                evidence=f"{header} not present in response headers",
                recommendation=recommendation,
            )

    for cookie in first_response.headers.get("set-cookie", []):
        lowered = cookie.lower()
        if "sess" not in lowered and "phpsessid" not in lowered:
            continue
        if "httponly" not in lowered:
            add_finding(
                findings,
                seen,
                top10,
                rule_id="cookie-missing-httponly",
                rank=2,
                severity="medium",
                title="Session cookie missing HttpOnly",
                endpoint=first_response.url,
                evidence=cookie[:200],
                recommendation="Set HttpOnly on session cookies.",
            )
        if target_url.startswith("https://") and "secure" not in lowered:
            add_finding(
                findings,
                seen,
                top10,
                rule_id="cookie-missing-secure",
                rank=3,
                severity="medium",
                title="Session cookie missing Secure flag",
                endpoint=first_response.url,
                evidence=cookie[:200],
                recommendation="Set Secure on session cookies served over HTTPS.",
            )

    for pattern in ERROR_DISCLOSURE_PATTERNS:
        match = pattern.search(first_response.body)
        if match:
            add_finding(
                findings,
                seen,
                top10,
                rule_id="error-disclosure",
                rank=6,
                severity="medium",
                title="Error disclosure in response body",
                endpoint=first_response.url,
                evidence=match.group(0),
                recommendation="Disable verbose errors and route details to server logs.",
            )
            break

    reflected_payload = "<svg/onload=alert(1337)>"
    reflected_response = client.get(
        target_url,
        params={"q": reflected_payload, "cobalt_probe": "reflected"},
    )
    if reflected_payload in reflected_response.body:
        add_finding(
            findings,
            seen,
            top10,
            rule_id="xss-reflection-generic",
            rank=7,
            severity="high",
            title="Reflected XSS-like behavior on query parameter",
            endpoint=reflected_response.url,
            evidence=reflected_payload,
            recommendation="Escape output and apply context-aware input validation.",
        )


def login_dvwa(
    client: WebClient,
    app_base: str,
    username: str,
    password: str,
) -> Tuple[bool, str]:
    login_url = urllib.parse.urljoin(app_base, "login.php")
    login_page = client.get(login_url)
    token = extract_token(login_page.body)

    form = {
        "username": username,
        "password": password,
        "Login": "Login",
    }
    if token:
        form["user_token"] = token

    submit = client.post(login_url, form)
    lowered = submit.body.lower()
    if "login failed" in lowered:
        return False, "DVWA login failed."

    verify = client.get(urllib.parse.urljoin(app_base, "index.php"))
    verify_lower = verify.body.lower()
    if "logout" in verify_lower:
        return True, f"DVWA login succeeded as '{username}'."
    if looks_like_login_page(verify.body):
        return False, "DVWA login did not establish an authenticated session."

    return True, f"DVWA login likely succeeded as '{username}'."


def set_dvwa_security_low(client: WebClient, app_base: str) -> Tuple[bool, str]:
    security_url = urllib.parse.urljoin(app_base, "security.php")
    page = client.get(security_url)
    token = extract_token(page.body)

    form = {
        "security": "low",
        "seclev_submit": "Submit",
    }
    if token:
        form["user_token"] = token

    response = client.post(security_url, form)
    lowered = response.body.lower()
    if "security level is currently low" in lowered or 'value="low"' in lowered:
        return True, "DVWA security level set to low."
    if looks_like_login_page(response.body):
        return False, "Could not set DVWA security level; authentication required."
    return False, "Could not confirm DVWA security level change to low."


def probe_dvwa_sqli(
    client: WebClient,
    app_base: str,
    top10: Dict[str, str],
    findings: List[Finding],
    seen: set,
) -> str:
    endpoint = urllib.parse.urljoin(app_base, "vulnerabilities/sqli/")
    baseline = client.get(endpoint, params={"id": "1", "Submit": "Submit"})
    injected = client.get(
        endpoint, params={"id": "1' OR '1'='1", "Submit": "Submit"}
    )
    if looks_like_login_page(injected.body):
        return "SQLi probe skipped (login required)."

    error = find_sql_error(injected.body)
    if error:
        add_finding(
            findings,
            seen,
            top10,
            rule_id="dvwa-sqli-error",
            rank=1,
            severity="high",
            title="SQL error exposed after injection payload",
            endpoint=injected.url,
            evidence=error,
            recommendation="Use parameterized queries and suppress SQL error disclosure.",
        )
        return "SQLi probe found SQL error evidence."

    base_rows = baseline.body.lower().count("surname:")
    injected_rows = injected.body.lower().count("surname:")
    if injected_rows > base_rows + 1:
        add_finding(
            findings,
            seen,
            top10,
            rule_id="dvwa-sqli-boolean",
            rank=1,
            severity="high",
            title="Possible SQL injection behavior on DVWA SQLi endpoint",
            endpoint=injected.url,
            evidence=f"rows baseline={base_rows}, injected={injected_rows}",
            recommendation="Use prepared statements and strict server-side validation.",
        )
        return "SQLi probe found row amplification evidence."

    return "SQLi probe did not produce a clear signal."


def probe_dvwa_reflected_xss(
    client: WebClient,
    app_base: str,
    top10: Dict[str, str],
    findings: List[Finding],
    seen: set,
) -> str:
    endpoint = urllib.parse.urljoin(app_base, "vulnerabilities/xss_r/")
    payload = "<svg/onload=alert('cobalt')>"
    response = client.get(endpoint, params={"name": payload, "Submit": "Submit"})
    if looks_like_login_page(response.body):
        return "Reflected XSS probe skipped (login required)."

    if payload in response.body:
        add_finding(
            findings,
            seen,
            top10,
            rule_id="dvwa-xss-reflected",
            rank=7,
            severity="high",
            title="Reflected XSS payload echoed unescaped",
            endpoint=response.url,
            evidence=payload,
            recommendation="HTML-encode output and enforce contextual output encoding.",
        )
        return "Reflected XSS probe found unescaped payload."

    return "Reflected XSS probe did not produce a clear signal."


def probe_dvwa_command_injection(
    client: WebClient,
    app_base: str,
    top10: Dict[str, str],
    findings: List[Finding],
    seen: set,
) -> str:
    endpoint = urllib.parse.urljoin(app_base, "vulnerabilities/exec/")
    marker = "COBALT_EXEC_1337"
    payload = f"127.0.0.1;echo {marker}"
    response = client.get(endpoint, params={"ip": payload, "Submit": "Submit"})
    if looks_like_login_page(response.body):
        return "Command injection probe skipped (login required)."

    if marker in response.body:
        add_finding(
            findings,
            seen,
            top10,
            rule_id="dvwa-command-injection",
            rank=1,
            severity="critical",
            title="Command injection output marker observed",
            endpoint=response.url,
            evidence=marker,
            recommendation="Avoid shell execution with untrusted input; use allowlists and safe APIs.",
        )
        return "Command injection probe found execution marker."

    return "Command injection probe did not produce a clear signal."


def probe_dvwa_file_inclusion(
    client: WebClient,
    app_base: str,
    top10: Dict[str, str],
    findings: List[Finding],
    seen: set,
) -> str:
    endpoint = urllib.parse.urljoin(app_base, "vulnerabilities/fi/")
    payload = "../../../../../../etc/passwd"
    response = client.get(endpoint, params={"page": payload})
    if looks_like_login_page(response.body):
        return "File inclusion probe skipped (login required)."

    if "root:x:0:0" in response.body:
        add_finding(
            findings,
            seen,
            top10,
            rule_id="dvwa-lfi-passwd",
            rank=5,
            severity="high",
            title="Local file inclusion/path traversal signal",
            endpoint=response.url,
            evidence="root:x:0:0 detected in response",
            recommendation="Constrain file access with allowlists and sanitize traversal characters.",
        )
        return "File inclusion probe found /etc/passwd content."

    return "File inclusion probe did not produce a clear signal."


def probe_dvwa_csrf(
    client: WebClient,
    app_base: str,
    top10: Dict[str, str],
    findings: List[Finding],
    seen: set,
) -> str:
    endpoint = urllib.parse.urljoin(app_base, "vulnerabilities/csrf/")
    response = client.get(endpoint)
    if looks_like_login_page(response.body):
        return "CSRF probe skipped (login required)."

    forms = parse_forms(response.body)
    if not forms:
        return "CSRF probe found no forms to evaluate."

    for form in forms:
        if form.method.lower() != "post":
            continue
        field_names = {field.name.lower() for field in form.fields}
        has_sensitive_action = (
            "password_new" in field_names
            or "password_conf" in field_names
            or "change" in field_names
            or "submit" in field_names
        )
        has_token = any("csrf" in name or "token" in name for name in field_names)
        if has_sensitive_action and not has_token:
            add_finding(
                findings,
                seen,
                top10,
                rule_id="dvwa-csrf-token-missing",
                rank=5,
                severity="medium",
                title="State-changing form appears to miss anti-CSRF token",
                endpoint=response.url,
                evidence=f"POST form fields: {sorted(field_names)}",
                recommendation="Use per-request CSRF tokens and validate origin/referrer where feasible.",
            )
            return "CSRF probe found a POST form without token fields."

    return "CSRF probe did not produce a clear signal."


def severity_sort_key(value: str) -> int:
    return SEVERITY_ORDER.get(value.lower(), 99)


def print_report(
    target_url: str,
    app_base: str,
    owasp_data: Dict[str, object],
    from_cache: bool,
    notes: List[str],
    findings: List[Finding],
) -> None:
    top10 = owasp_data.get("top10", {})
    if not isinstance(top10, dict):
        top10 = {}

    print(f"Target: {target_url}")
    print(f"Resolved app base: {app_base}")
    print(f"OWASP source: {'cache hit' if from_cache else 'refreshed via invictus'}")
    print(f"OWASP query: {owasp_data.get('query', '(unknown)')}")

    links = owasp_data.get("links", [])
    if isinstance(links, list) and links:
        print("OWASP links:")
        for index, link in enumerate(links, start=1):
            print(f"{index}. {link}")

    print("\nOWASP Top 10 used for mapping:")
    for rank in range(1, 11):
        label = top10.get(str(rank), FALLBACK_2017.get(str(rank), "Unknown"))
        print(f"A{rank}: {label}")

    print("\nProbe notes:")
    if notes:
        for note in notes:
            print(f"- {note}")
    else:
        print("- (none)")

    if not findings:
        print("\nFindings: none (no strong probe signals detected).")
        return

    ordered = sorted(
        findings,
        key=lambda item: (
            item.rank,
            severity_sort_key(item.severity),
            item.endpoint,
            item.rule_id,
        ),
    )

    print(f"\nFindings: {len(ordered)} total")
    current_rank = None
    for finding in ordered:
        if finding.rank != current_rank:
            current_rank = finding.rank
            print(f"\nA{finding.rank}: {finding.category}")
        print(
            f"- [{finding.severity.upper()}] {finding.title} ({finding.endpoint})"
        )
        print(f"  Rule: {finding.rule_id}")
        print(f"  Evidence: {finding.evidence}")
        print(f"  Recommendation: {finding.recommendation}")


def main() -> int:
    parser = argparse.ArgumentParser(
        description=(
            "Run a lightweight pentest of a deployed webapp URL, reusing "
            "OWASP hints from invictus for finding categorization."
        )
    )
    parser.add_argument(
        "--target",
        required=True,
        help="Target webapp URL (for example http://127.0.0.1:8080).",
    )
    parser.add_argument(
        "--year",
        type=int,
        default=DEFAULT_YEAR,
        help="OWASP year queried through invictus (default: 2017).",
    )
    parser.add_argument(
        "--max-links",
        type=int,
        default=DEFAULT_MAX_LINKS,
        help="Number of links invictus reads when refreshing OWASP data (default: 3).",
    )
    parser.add_argument(
        "--refresh-owasp",
        action="store_true",
        help="Force refresh OWASP data even if cache exists.",
    )
    parser.add_argument(
        "--username",
        default="admin",
        help="DVWA login username (default: admin).",
    )
    parser.add_argument(
        "--password",
        default="password",
        help="DVWA login password (default: password).",
    )
    parser.add_argument(
        "--skip-login",
        action="store_true",
        help="Skip DVWA login attempt and run anonymous probes only.",
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=DEFAULT_TIMEOUT,
        help="HTTP timeout in seconds (default: 15).",
    )
    parser.add_argument(
        "--json-output",
        help="Optional output path to write JSON report.",
    )
    args = parser.parse_args()

    if args.year < 2003 or args.year > 2100:
        print("Year is out of supported range (2003-2100).", file=sys.stderr)
        return 2
    if args.timeout < 1 or args.timeout > 120:
        print("Timeout must be in range 1-120 seconds.", file=sys.stderr)
        return 2

    try:
        target_url = normalize_target_url(args.target)
    except ValueError as exc:
        print(f"[ERROR] {exc}", file=sys.stderr)
        return 2

    max_links = max(1, min(args.max_links, 5))

    try:
        owasp_data, from_cache = ensure_owasp_data(
            year=args.year,
            max_links=max_links,
            refresh=args.refresh_owasp,
        )
    except Exception as exc:
        print(f"[ERROR] Could not prepare OWASP data: {exc}", file=sys.stderr)
        return 1

    top10 = owasp_data.get("top10", {})
    if not isinstance(top10, dict):
        print("[ERROR] OWASP data format is invalid: top10 is missing.", file=sys.stderr)
        return 1

    client = WebClient(timeout=args.timeout)
    findings: List[Finding] = []
    notes: List[str] = []
    seen = set()

    try:
        first_response = client.get(target_url)
    except Exception as exc:
        print(f"[ERROR] Target request failed: {exc}", file=sys.stderr)
        return 1

    app_base = derive_app_base(first_response.url)
    run_generic_checks(
        client=client,
        target_url=target_url,
        first_response=first_response,
        top10=top10,
        findings=findings,
        seen=seen,
    )

    is_dvwa = is_dvwa_response(first_response)
    if is_dvwa:
        notes.append("DVWA fingerprint detected.")
        authenticated = False
        if args.skip_login:
            notes.append("DVWA login skipped by flag.")
        else:
            try:
                authenticated, message = login_dvwa(
                    client=client,
                    app_base=app_base,
                    username=args.username,
                    password=args.password,
                )
                notes.append(message)
            except Exception as exc:
                notes.append(f"DVWA login probe failed: {exc}")

        if authenticated:
            try:
                _, security_message = set_dvwa_security_low(client, app_base)
                notes.append(security_message)
            except Exception as exc:
                notes.append(f"DVWA security-level probe failed: {exc}")

        probe_steps = [
            ("DVWA SQLi", probe_dvwa_sqli),
            ("DVWA reflected XSS", probe_dvwa_reflected_xss),
            ("DVWA command injection", probe_dvwa_command_injection),
            ("DVWA file inclusion", probe_dvwa_file_inclusion),
            ("DVWA CSRF", probe_dvwa_csrf),
        ]
        for label, handler in probe_steps:
            try:
                notes.append(
                    handler(
                        client=client,
                        app_base=app_base,
                        top10=top10,
                        findings=findings,
                        seen=seen,
                    )
                )
            except Exception as exc:
                notes.append(f"{label} probe failed: {exc}")
    else:
        notes.append("DVWA fingerprint not detected; DVWA-specific probes skipped.")

    print_report(
        target_url=target_url,
        app_base=app_base,
        owasp_data=owasp_data,
        from_cache=from_cache,
        notes=notes,
        findings=findings,
    )

    if args.json_output:
        output_path = Path(args.json_output).resolve()
        output_path.parent.mkdir(parents=True, exist_ok=True)
        payload = {
            "target": target_url,
            "app_base": app_base,
            "owasp_data": owasp_data,
            "from_cache": from_cache,
            "notes": notes,
            "finding_count": len(findings),
            "findings": [asdict(item) for item in findings],
        }
        output_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        print(f"\nJSON report written to: {output_path}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
